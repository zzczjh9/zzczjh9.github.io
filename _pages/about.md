---
layout: about
title: about
permalink: /
subtitle: Undergraduate Student in Electronic and Information Engineering at Imperial College London

profile:
  align: right
  image: my_photo.jpg  # Change this to your new image filename
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>London, United Kingdom</p>
    <p>zecheng.zhu23@imperial.ac.uk</p>
    <p>Imperial College London</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Hello there! ðŸ‘‹

I'm **Zecheng Zhu**, an undergraduate student pursuing a Bachelor's degree in Electronic and Information Engineering at Imperial College London.

During my undergraduate studies, I am fortunate to work with [Prfs. Zhongyu Li](https://zyliatzju.github.io/) and [Prfs. Yue Wang](https://ywang-zju.github.io/) on Legged Robot and Reinforcement Learning, and intern at Lightwheel AI on Reinforcement Learning and Simulation Framework.

My research interests lies in the intersection of learning and Robotics, aiming to excavate the potential of adaptivity and agility of robots.

Find more in my [Curriculum Vitae](/assets/pdf/CV_Zecheng_Zhu-2.pdf).



**Languages**: Python, C++, C, SQL, SystemVerilog  
**Skills**: Isaac Sim/Gym/Lab, PyTorch, ROS, Linux, Git, Embedded Platforms (ESP/STM)

### Selected Projects

### GenlocoV2: Transformer-based Generalized Locomotion Controller
**Research Project** | *Current*

Transformer-based generalized locomotion controller for morphology & topology-agnostic policy learning across diverse robotic embodiments including quadrupeds, bipeds, and humanoids. Implemented multi-robot training pipeline with procedurally generated morphological variations and novel graph-based robot representation architecture.

[View Project â†’](/projects/#genlocov2)

### Autonomous Campus Tour Guide Robot
**Academic Project** | *2024*

Award-winning autonomous robot with vision, voice, and cloud integration for campus tours. Features self-balancing mobility using dual-loop PID/LQR control achieving <15cm positional accuracy, YOLOv8 Nano vision system, cross-platform Flutter app, and AWS cloud infrastructure.

[View Project â†’](/projects/#campus-tour-robot)


